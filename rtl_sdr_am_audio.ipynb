{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as  np\n",
    "import sounddevice as sd\n",
    "from copy import copy\n",
    "from rtlsdr import RtlSdr \n",
    "import threading\n",
    "from queue import Queue\n",
    "import speech_recognition as speechreg\n",
    "import scipy.io.wavfile as wav\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get string from local file\n",
    "WITAI_KEY = \"\"\n",
    "with open(\"witai_key.txt\", \"r\") as file:\n",
    "    WITAI_KEY = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_SDR():\n",
    "    try: \n",
    "        sdr.close()\n",
    "        print(\"Closed old SDR\")\n",
    "    except NameError:\n",
    "       print(\"No SDR instance found\")\n",
    "    \n",
    "    sdr = RtlSdr() \n",
    "    return sdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sdr_options(sdr, fc, Tmax):\n",
    "    fsps = 256*256*16\n",
    "    faudiosps = 48000 # audio sampling frequency (for output)\n",
    "\n",
    "    # specify sampling frequency\n",
    "    dt = 1.0/fsps # time step size between samples\n",
    "    nyquist = fsps /2.0\n",
    "    \n",
    "    Tmax = Tmax  # Duration\n",
    "    \n",
    "    N = round(fsps*Tmax) # N must be a multiple of 256\n",
    "    print(\"The number of samples to collect, N= \",N)\n",
    "    \n",
    "    sdr.sample_rate = fsps \n",
    "    sdr.center_freq = fc\n",
    "\n",
    "    sdr.gain = 0.9 # valid according to sdr.valid_gains_db\n",
    "    print(\"Gain (0==auto)  : \", sdr.gain)\n",
    "    print(\"Sample Rate     : \", sdr.sample_rate)\n",
    "    print(\"Center frequency: \", sdr.center_freq)\n",
    "    return faudiosps, N, fsps, nyquist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(sdr, N, fc, Tmax, fsps, nyquist):\n",
    "    samples = ((np.zeros((N))+1j)-1j) # Trick it into being an array of complex zeros\n",
    "    sdr.center_freq = fc\n",
    "    \n",
    "    RF_record_start_time = time.time()\n",
    "    samples = sdr.read_samples(N) # Collect N samples...N must be multiple of 256end_time = time.time()\n",
    "    RF_record_end_time = time.time()\n",
    "    RF_record_duration_actual = RF_record_end_time - RF_record_start_time\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrum(N, samples, fc, nyquist):\n",
    "    freqs = np.zeros((N))\n",
    "    spectrum = ((np.zeros((N))+1j)-1j)\n",
    "    maxval = 0.0\n",
    "    maxind = 0.0\n",
    "    \n",
    "    spectrum = np.fft.fftshift(np.fft.fft(samples))\n",
    "    maxval = np.amax(np.abs(spectrum))\n",
    "    maxindi = np.argmax(np.abs(spectrum))\n",
    "    freqs = np.linspace(fc-nyquist,fc+nyquist,len(spectrum))\n",
    "    return spectrum, freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpassmask3(N,fsps,fcutoff, bandwidth):\n",
    "    fcutoff_n = fcutoff / fsps # fcutoff, normalized\n",
    "    pbfw = round(2*bandwidth*N / fsps)\n",
    "    sbw = int((N-pbfw)/2)\n",
    "    res = np.concatenate((np.zeros(sbw),np.ones(pbfw),np.zeros(sbw)))\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bandpass_mask(N, fsps, fcutoff, spectrum, freqs, xwidth):\n",
    "    # Create and plot the bandpass mask\n",
    "    fcutoff = fcutoff # Cutoff frequency of filter 100kHz\n",
    "    bpm = bandpassmask3(N, fsps, fcutoff, xwidth)\n",
    "    height = np.max(np.abs(spectrum))\n",
    "    return bpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(freqs, spectrum, bpm):\n",
    "    filteredspectrum = spectrum * bpm\n",
    "    filteredsignal = np.fft.ifft(np.fft.fftshift(filteredspectrum)) # Good results\n",
    "    return filteredspectrum, filteredsignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def am_envelope_detection(filteredsignal):\n",
    "    # This is not fully working. Worth exploring scipy's butterworth filter, but could not make that work."
    "    return np.abs(filteredsignal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squelch(filteredsignal, N):\n",
    "    theta = np.arctan2(filteredsignal.imag,filteredsignal.real)\n",
    "    abssignal = np.abs(filteredsignal)\n",
    "    meanabssignal = np.mean(abssignal)\n",
    "    thetasquelched = copy(theta)\n",
    "    filteredsquelched = copy(filteredsignal)\n",
    "    for i in range(N):\n",
    "        if (abssignal[i]<(meanabssignal/3.0)):\n",
    "            filteredsquelched[i] = 0.0\n",
    "            thetasquelched[i] = 0.0\n",
    "    mins = int(2.1e3)\n",
    "    maxs = int(2.7e3)\n",
    "    alphaval = 1.0\n",
    "    \n",
    "    # No squelching version\n",
    "    derivthetap0 = np.convolve([1,-1],theta,'same')\n",
    "    derivthetapp = np.convolve([1,-1],(theta+np.pi) % (2*np.pi),'same')\n",
    "    derivthetap0[100:110]-derivthetapp[100:110]\n",
    "    \n",
    "    # Squelching version...\n",
    "    # deriv (theta plus 0)\n",
    "    derivthetap0 = np.convolve([1,-1],thetasquelched,'same')\n",
    "    derivthetapp = np.convolve([1,-1],(thetasquelched+np.pi) % (2*np.pi),'same')\n",
    "    \n",
    "    # The 0, +pi comparison method\n",
    "    # deriv (theta plus pi)\n",
    "    derivtheta = np.zeros(len(derivthetap0))\n",
    "    for i in range(len(derivthetap0)):\n",
    "        if (abs(derivthetap0[i])<abs(derivthetapp[i])):\n",
    "            derivtheta[i] = derivthetap0[i] \n",
    "        else:\n",
    "            derivtheta[i] = derivthetapp[i] \n",
    "    cdtheta = copy(derivtheta)\n",
    "    spikethresh = 2\n",
    "    for i in range(1,len(derivtheta)-1):\n",
    "        if (abs(derivtheta[i])>spikethresh):\n",
    "            cdtheta[i] = (derivtheta[i-1]+derivtheta[i+1])/2.0\n",
    "    return cdtheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(fsps, faudiosps, cdtheta):\n",
    "    dsf = round(fsps/faudiosps) # round(1048576/48000)=22\n",
    "    dscdtheta = cdtheta[::dsf] # downsample by 22 (or whatever dsf is)\n",
    "    dscdtheta2 = copy(dscdtheta)\n",
    "    for i in range(len(dscdtheta2)):\n",
    "        dscdtheta2[i] = np.sum(cdtheta[i*dsf:(i+1)*dsf])/dsf\n",
    "    dscdtheta = copy(dscdtheta2)\n",
    "    return dscdtheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play Audio\n",
    "#faudiosps defined at top (eg 48000)\n",
    "def play_audio(faudiosps, dscdtheta):\n",
    "    dt_audio = 1/faudiosps\n",
    "    myaudio = dscdtheta\n",
    "    start_time = time.time()\n",
    "    sd.play(10*myaudio,faudiosps,blocking=True)\n",
    "    end_time = time.time()\n",
    "    time_actual = end_time-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multithreading Helpers\n",
    "def sample_audio(sdr, N, fc, Tmax, fsps, nyquist, samples_q):\n",
    "    while True:\n",
    "        samples = get_samples(sdr, N, fc, Tmax, fsps, nyquist)\n",
    "        samples_q.put(samples)\n",
    "\n",
    "def process_audio(fc, fsps, faudiosps, nyquist, fcutoff, xwidth, samples_q, audio_q, am):\n",
    "    while True:\n",
    "        if samples_q.qsize() > 1:\n",
    "            samples = samples_q.get()\n",
    "            spectrum, freqs = get_spectrum(len(samples), samples, fc, nyquist)\n",
    "            bpm = get_bandpass_mask(len(samples), fsps, fcutoff, spectrum, freqs, xwidth)\n",
    "            filteredspectrum, filteredsignal = apply_filter(freqs, spectrum, bpm)\n",
    "            if (am):\n",
    "                filteredsignal = am_envelope_detection(filteredsignal)\n",
    "            cdtheta = squelch(filteredsignal, len(samples))\n",
    "            dscdtheta = downsample(fsps, faudiosps, cdtheta)\n",
    "            audio_q.put(dscdtheta)\n",
    "            speech_q.put(dscdtheta)\n",
    "\n",
    "def play_audio(faudiosps, audio_q, speech_q):\n",
    "    while True:\n",
    "        if not audio_q.empty():\n",
    "            dscdtheta = audio_q.get()\n",
    "            audio_played.set()\n",
    "            sd.play(0.25 * dscdtheta, faudiosps, blocking=True)\n",
    "\n",
    "def output_speech(faudiosps, speech_q):\n",
    "    speech = speechreg.Recognizer()\n",
    "\n",
    "    while True:\n",
    "        audio_played.wait()\n",
    "        audio_played.clear()\n",
    "        if not speech_q.empty():\n",
    "            audio_data = speech_q.get()\n",
    "            scaled_audio = np.interp(audio_data, (np.min(audio_data), np.max(audio_data)), (-32768, 32767))\n",
    "            audio_np = np.array(scaled_audio, dtype=np.int16)\n",
    "            wav.write(\"output.wav\", faudiosps, audio_np)\n",
    "            with speechreg.AudioFile(\"output.wav\") as src:\n",
    "                audio_data2 = speech.record(src)\n",
    "                try:\n",
    "                    text = speech.recognize_wit(audio_data2, key=WITAI_KEY, show_all=True)\n",
    "                    print(text['_text'])\n",
    "                except BaseException as error:\n",
    "                    print(\"error translating speech to text:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No SDR instance found\n",
      "The number of samples to collect, N=  5242880\n",
      "Gain (0==auto)  :  0.9\n",
      "Sample Rate     :  1048576.0\n",
      "Center frequency:  97300000\n",
      "Starting Sampling\n",
      "Starting Processing\n",
      "Starting Playback\n",
      "Starting Speech-To-Text\n",
      "Considering every option is the address the semibird endorsement in the light\n",
      "Evalation that Sammy Bird maybe may have. Did a little bit of the old stolen valor. Do you know\n",
      "The guy who did stolen ballots. Really? When I was worked in security tomorrow, it's a great story to finish\n",
      "Remember the military\n",
      "Pretends that they did some heroic action. Wearing a badge or or a metal you didn't win and it's\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "audio_played = threading.Event()\n",
    "### Initialization Steps\n",
    "sdr = init_SDR()\n",
    "\n",
    "fc = 97.3e6\n",
    "fcutoff = 200000\n",
    "xwidth = 200000\n",
    "\n",
    "am = True\n",
    "if am:\n",
    "    fc = 118e6\n",
    "    fcutoff = 118e6\n",
    "    xwidth = 8000\n",
    "\n",
    "Tmax = 5\n",
    "faudiosps, N, fsps, nyquist = select_sdr_options(sdr, fc, Tmax)\n",
    "\n",
    "samples_q = Queue()\n",
    "audio_q = Queue()\n",
    "speech_q = Queue()\n",
    "\n",
    "sample_thread = threading.Thread(target=sample_audio, args=(sdr, N, fc, Tmax, fsps, nyquist, samples_q))\n",
    "process_thread = threading.Thread(target=process_audio, args=(fc, fsps, faudiosps, nyquist, fcutoff, xwidth, samples_q, audio_q, am))\n",
    "playback_thread = threading.Thread(target=play_audio, args=(faudiosps, audio_q, speech_q))\n",
    "speech_thread = threading.Thread(target=output_speech, args=(faudiosps, speech_q))\n",
    "\n",
    "print(\"Starting Sampling\")\n",
    "sample_thread.start()\n",
    "\n",
    "print(\"Starting Processing\")\n",
    "process_thread.start()\n",
    "\n",
    "print(\"Starting Playback\")\n",
    "playback_thread.start()\n",
    "\n",
    "print(\"Starting Speech-To-Text\")\n",
    "speech_thread.start()\n",
    "\n",
    "sample_thread.join()\n",
    "process_thread.join()\n",
    "playback_thread.join()\n",
    "speech_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not reachable through main execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is for testing transcription of a saved ATC audio file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as  np\n",
    "import sounddevice as sd\n",
    "import speech_recognition as speechreg\n",
    "import scipy.io.wavfile as wav\n",
    "import pandas as pd\n",
    "\n",
    "# Get string from local file\n",
    "WITAI_KEY = \"\"\n",
    "with open(\"witai_key.txt\", \"r\") as file:\n",
    "    WITAI_KEY = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio excerpts from: https://www.youtube.com/watch?v=wUE8G4zpohk\n",
    "\n",
    "# file_path = \"example_atc1.wav\"\n",
    "# expected = \"Southwest 1860, company pushing out of Bravo 12, \\n\" \\\n",
    "#            \"is where that you want to push? \\n\" \\\n",
    "#            \"Reference them, push your discretion, runway 4A. \\n\" \\\n",
    "#            \"Push your discretion, uhh 4A, Southwest 1860, \\n\" \\\n",
    "#            \"watch out for company on Bravo 12.\"\n",
    "\n",
    "# file_path = \"example_atc2.wav\"\n",
    "# expected = \"Airport 84, roger. And uh, \\n\" \\\n",
    "#            \"the escort that called clear, \\n\" \\\n",
    "#            \"was that 909 or 979?\"\n",
    "\n",
    "file_path = \"example_atc3.wav\"\n",
    "expected = \"Southwest 1860, Midway Ground, Runway 4 Right, \\n\" \\\n",
    "           \"taxi via Tango Yankee, \\n\" \\\n",
    "           \"cross Runways 31 Right, 31 Center, and 31 Left.\"\n",
    "\n",
    "print(\"Expected Text:\")\n",
    "print(expected)\n",
    "print()\n",
    "sample_rate, data = wav.read(file_path)\n",
    "sd.play(data, sample_rate)\n",
    "\n",
    "speech = speechreg.Recognizer()\n",
    "with speechreg.AudioFile(file_path) as src:\n",
    "    \n",
    "    audio_data = speech.record(src)\n",
    "    try:\n",
    "        text = speech.recognize_wit(audio_data, key=WITAI_KEY, show_all=True)\n",
    "        print(\"Transcription:\")\n",
    "        print(text['_text'])\n",
    "    except BaseException as error:\n",
    "        print(\"error translating speech to text:\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
